# --  Mongo DB                  --
mongo.replica.set=localhost:27017
mongo.client.user=argus
mongo.client.passwd=argus
mongo.client.authdb=argus
mongo.database.name=argus

# --  MySQL                     --
druid.url=jdbc:mysql://localhost:3306/pomp_test?useUnicode=true&characterEncoding=UTF-8
druid.username=root
druid.password=sql-1243!

# --  kafka Config              --
kafka.bootstrap.servers=localhost:9092
consumer.group.id=group3
kafka.request.timeout.ms=150000
kafka.session.timeout.ms=120000
max.partition.fetch.bytes=262144

#-----------ThreadPool----------------
tp.maxPoolSize=20
tp.corePoolSize=20
tp.allowCoreThreadTimeOut=false
tp.queueCapacity=1000

exception.warnTimes = 3
exception.errorTimes =10

timeOut=120000

# --  Logback xml Config        --
logfile.path=/module/logs
#output mode: "CONSOLE" for development /"FILE" for service
logback.output.mode=info

# --  Zookeeper                 --
dubbo.ezsec.address=localhost:2181

# --  HDFS                      --
hdfs.defaultFS=hdfs://mycluster1
hdfs.nameservices=mycluster1
hdfs.namenodes.cluster.key=dfs.ha.namenodes.mycluster1
hdfs.namenodes.cluster=namenode1,namenode2
hdfs.namenode1.key=dfs.namenode.rpc-address.mycluster1.namenode1
hdfs.namenode1.ip=pomp-argus-3:8020
hdfs.namenode2.key=dfs.namenode.rpc-address.mycluster1.namenode2
hdfs.namenode2.ip=pomp-argus-4-1:8020
hdfs.failover.proxy.provider.key=fs.client.failover.proxy.provider.mycluster1
hdfs.maxFileLength=125829120
hdfs.fileExtendName=.tmp
hdfs.separator=|

#-----------standby----------------
standby.connectString=22.188.9.142:2181,22.188.9.131:2181,22.188.14.123:2181
standby.sessionTimeoutMs=6000
standby.connectionTimeoutMs=3000
standby.latchPath=/leader
standby.baseSleepTimeMs=1000
standby.maxRetries=3

#-------------topic-------------------
invalidTopic=invalid_parse_data
infoTopic=parse_statistic_info

#---------------statistics-----------------------
statisticsInfoInterval=60000
statisticsInfoCount=500000

#---------------ES--------------------
es.cluster.name=elasticsearch
es.cluster.nodes=
es.client.transport.sniff=false
es.flush.docnum=10000
es.flush.interval=2
es.flush.size=5m
es.concurrent.requests=3

#---------------Redis--------------------
redis.hostAndPort1=22.188.9.144:26379
redis.hostAndPort2=22.188.14.124:26379
redis.hostAndPort3=22.188.14.125:26379
redis.clusterName=mymaster
redis.password=4ACHb0GYI9+IWdWRZcUYxQ==